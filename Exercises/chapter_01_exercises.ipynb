{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction to Statistical Inference - Exercises\n",
    "\n",
    "<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white;'>\n",
    "<h1 style='margin: 0; font-size: 2.5em;'>PLAI Academy</h1>\n",
    "<p style='margin: 10px 0 0 0; font-size: 1.2em; opacity: 0.9;'>Statistical Inference • Chapter 1 Exercises</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise Structure\n",
    "\n",
    "This notebook contains **20 exercises** organized into four sections:\n",
    "\n",
    "1. **Exercises 1-5**: Fundamental concepts directly from chapter material\n",
    "2. **Exercises 6-10**: Advanced problems from classical statistics literature\n",
    "3. **Exercises 11-15**: Applications in AI/Machine Learning\n",
    "4. **Exercises 16-20**: Contemporary problems (2025+)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='whitegrid', palette='husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Fundamental Concepts (Exercises 1-5)\n",
    "\n",
    "### Exercise 1.1: Population vs Sample\n",
    "\n",
    "A quality control inspector wants to estimate the average weight of cereal boxes produced in a factory. The factory produces 10,000 boxes per day.\n",
    "\n",
    "**Tasks:**\n",
    "1. Define the population and a potential sample\n",
    "2. Generate a population of 10,000 box weights with mean μ = 500g and standard deviation σ = 15g\n",
    "3. Draw a random sample of n = 30 boxes\n",
    "4. Calculate the sample mean and compare it to the population mean\n",
    "5. Repeat step 3-4 ten times. What do you observe about the sample means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Sampling Distribution Simulation\n",
    "\n",
    "**Reference**: [Using Simulations to Explore Sampling Distributions (PMC, 2025)](https://pmc.ncbi.nlm.nih.gov/articles/PMC12549070/)\n",
    "\n",
    "This exercise demonstrates how sampling distributions illustrate the behavior of statistics across repeated samples.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a population that follows N(100, 225) (mean=100, variance=225)\n",
    "2. Draw 1000 samples of size n=25 from this population\n",
    "3. Calculate the sample mean for each sample\n",
    "4. Plot the distribution of these 1000 sample means\n",
    "5. Compare the mean and standard deviation of the sampling distribution to theoretical values:\n",
    "   - E[X̄] = μ = 100\n",
    "   - SE(X̄) = σ/√n = 15/√25 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Central Limit Theorem with Non-Normal Data\n",
    "\n",
    "The Central Limit Theorem states that sample means are approximately normal regardless of the population distribution for large n.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create an exponential population with λ = 0.5 (mean = 2, variance = 4)\n",
    "2. For sample sizes n = [5, 10, 30, 50, 100]:\n",
    "   - Draw 1000 samples of size n\n",
    "   - Calculate the mean of each sample\n",
    "   - Plot the distribution of sample means\n",
    "3. Observe how the sampling distribution becomes more normal as n increases\n",
    "4. Calculate skewness for each sampling distribution to quantify normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4: Confidence Intervals\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate a sample of n=50 from N(μ=75, σ=12)\n",
    "2. Calculate a 95% confidence interval for the population mean using:\n",
    "   - X̄ ± t_{α/2, n-1} × (s/√n)\n",
    "3. Repeat this process 100 times, creating 100 different confidence intervals\n",
    "4. Plot all 100 confidence intervals and color them:\n",
    "   - Green if they contain the true mean (μ=75)\n",
    "   - Red if they don't\n",
    "5. Calculate the coverage rate (proportion that contain μ). Does it match the 95% confidence level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5: Hypothesis Testing and P-values\n",
    "\n",
    "A researcher claims that a new teaching method increases test scores. Historical data shows the population mean is μ₀ = 70. After implementing the new method, a sample of 36 students has a mean score of 73.5 with standard deviation s = 8.\n",
    "\n",
    "**Tasks:**\n",
    "1. State the null and alternative hypotheses\n",
    "2. Calculate the test statistic: t = (X̄ - μ₀)/(s/√n)\n",
    "3. Calculate the p-value for a one-sided test\n",
    "4. Make a decision at α = 0.05 significance level\n",
    "5. Simulate the null distribution (assuming H₀ is true) and visualize where your test statistic falls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Advanced Statistical Problems (Exercises 6-10)\n",
    "\n",
    "### Exercise 1.6: Power Analysis\n",
    "\n",
    "**Reference**: [Statistical Inference - Casella & Berger](https://www.ctanujit.org/uploads/2/5/3/9/25393293/_solutions_manual_of_casella_berger.pdf)\n",
    "\n",
    "Statistical power is the probability of correctly rejecting a false null hypothesis.\n",
    "\n",
    "**Tasks:**\n",
    "1. Consider testing H₀: μ = 100 vs H₁: μ = 105 with σ = 15, n = 25, α = 0.05\n",
    "2. Calculate the critical value for rejecting H₀\n",
    "3. Calculate the probability of Type II error (β) when the true mean is 105\n",
    "4. Calculate power = 1 - β\n",
    "5. Create a power curve showing power for true means ranging from 100 to 110\n",
    "6. How does increasing sample size to n = 50 affect power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.7: Comparing Two Populations\n",
    "\n",
    "Two manufacturing processes produce light bulbs. Process A has been tested extensively with known mean lifetime μ_A = 1000 hours and σ_A = 100 hours. Process B is new.\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate data for Process A (n=40) and Process B (n=40, with true mean=1050, σ=100)\n",
    "2. Perform a two-sample t-test to determine if Process B has a different mean lifetime\n",
    "3. Calculate the 95% confidence interval for the difference in means\n",
    "4. Repeat this experiment 1000 times and calculate:\n",
    "   - The proportion of times you correctly reject H₀ (empirical power)\n",
    "   - The distribution of p-values when H₀ is false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.8: Chi-Squared Distribution and Sample Variance\n",
    "\n",
    "For a normal population, the sample variance follows a chi-squared distribution:\n",
    "(n-1)s²/σ² ~ χ²(n-1)\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate 5000 samples of size n=20 from N(50, 100) (variance σ²=100)\n",
    "2. For each sample, calculate s² and the standardized quantity (n-1)s²/σ²\n",
    "3. Plot the histogram of these standardized quantities\n",
    "4. Overlay the theoretical χ²(19) distribution\n",
    "5. Use this relationship to construct a 95% confidence interval for σ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.9: Multiple Testing Problem\n",
    "\n",
    "When conducting multiple hypothesis tests, the probability of at least one Type I error increases.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate 20 independent hypothesis tests where all null hypotheses are true\n",
    "2. For each test:\n",
    "   - Generate data from N(0, 1) with n=30\n",
    "   - Test H₀: μ = 0 at α = 0.05\n",
    "3. Count how many tests incorrectly reject H₀\n",
    "4. Repeat this entire process 1000 times\n",
    "5. What is the probability of at least one false rejection? Compare to theoretical: 1 - (1-0.05)²⁰\n",
    "6. Apply Bonferroni correction (α/20) and recalculate the family-wise error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.10: Sample Size Determination\n",
    "\n",
    "**Tasks:**\n",
    "1. You want to estimate the population mean with a margin of error E = 2 at 95% confidence\n",
    "2. From a pilot study, you estimate σ = 12\n",
    "3. Calculate the required sample size: n = (z_{α/2} × σ / E)²\n",
    "4. Verify this by simulation:\n",
    "   - Generate 1000 samples of the calculated size\n",
    "   - For each, construct a 95% CI\n",
    "   - Calculate the average width of these CIs\n",
    "5. What happens to required sample size if you want E = 1? E = 0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: AI/Machine Learning Applications (Exercises 11-15)\n",
    "\n",
    "### Exercise 1.11: Train-Test Split and Sampling Distributions\n",
    "\n",
    "In machine learning, we split data into training and test sets. Understanding sampling variation is crucial.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a dataset of 1000 samples with a known relationship: y = 2x + 3 + noise\n",
    "2. Perform 100 different random 80-20 train-test splits\n",
    "3. For each split, fit a linear model on training data and evaluate on test data\n",
    "4. Plot the distribution of:\n",
    "   - Training R² scores\n",
    "   - Test R² scores\n",
    "5. Calculate the mean and standard deviation of test performance\n",
    "6. What does this tell you about the sampling distribution of model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.12: Bias-Variance Decomposition in Practice\n",
    "\n",
    "**Reference**: [Reconciling modern machine learning and bias-variance trade-off (PNAS)](https://www.pnas.org/doi/10.1073/pnas.1903070116)\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate data: y = sin(2πx) + ε where ε ~ N(0, 0.1²)\n",
    "2. For polynomial models of degree d = [1, 2, 5, 10, 20]:\n",
    "   - Generate 100 training datasets of size n=50\n",
    "   - Fit the model to each training set\n",
    "   - Evaluate predictions at a fixed test point x=0.5\n",
    "3. For each model degree, calculate:\n",
    "   - Bias² = (E[ŷ] - y_true)²\n",
    "   - Variance = Var(ŷ)\n",
    "   - MSE = Bias² + Variance + σ²\n",
    "4. Plot bias², variance, and total MSE vs model complexity\n",
    "5. Identify the optimal model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.13: Confidence Intervals for Model Performance\n",
    "\n",
    "Model performance metrics are statistics with sampling distributions.\n",
    "\n",
    "**Tasks:**\n",
    "1. Train a classification model on a dataset (use sklearn's make_classification)\n",
    "2. Evaluate accuracy on a test set of size n=200\n",
    "3. Construct a 95% confidence interval for the true accuracy using:\n",
    "   - Normal approximation: p̂ ± z_{α/2} × √(p̂(1-p̂)/n)\n",
    "   - Wilson score interval (better for proportions)\n",
    "4. Repeat the experiment 1000 times with different random seeds\n",
    "5. Verify that approximately 95% of the CIs contain the true population accuracy\n",
    "6. How does sample size affect CI width?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.14: Hypothesis Testing for Model Comparison\n",
    "\n",
    "**Tasks:**\n",
    "1. Train two different models (e.g., logistic regression vs random forest) on the same dataset\n",
    "2. Use 10-fold cross-validation to get 10 accuracy measurements for each model\n",
    "3. Perform a paired t-test to determine if one model is significantly better:\n",
    "   - H₀: μ_diff = 0 (no difference in performance)\n",
    "   - H₁: μ_diff ≠ 0 (one model is better)\n",
    "4. Calculate the p-value and effect size (Cohen's d)\n",
    "5. Discuss: Why is a paired test more appropriate than an independent samples test here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.15: P-values and Model Selection\n",
    "\n",
    "In feature selection, we often test many features for significance, leading to multiple testing issues.\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate a dataset with 100 features, where only 5 are truly predictive\n",
    "2. For each feature, perform a t-test against the target variable\n",
    "3. Sort features by p-value and select features with p < 0.05\n",
    "4. How many false positives do you get?\n",
    "5. Apply False Discovery Rate (FDR) control using Benjamini-Hochberg procedure\n",
    "6. Compare the selected features before and after FDR correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Contemporary Problems (2025+)\n",
    "\n",
    "### Exercise 1.16: Uncertainty Quantification in LLMs\n",
    "\n",
    "**Reference**: [Uncertainty Quantification for Large Language Models (ACL 2025)](https://aclanthology.org/2025.acl-tutorials.3/)\n",
    "\n",
    "Modern LLMs need to quantify uncertainty in their predictions.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate an LLM classification task with 4 classes\n",
    "2. Generate 1000 predictions where the model outputs probability distributions over classes\n",
    "3. For each prediction, calculate:\n",
    "   - Predictive entropy: H = -Σ p_i log(p_i)\n",
    "   - Maximum probability\n",
    "4. Establish a confidence threshold based on entropy\n",
    "5. Create a calibration plot:\n",
    "   - Bin predictions by confidence level\n",
    "   - Compare predicted confidence to actual accuracy\n",
    "6. Discuss: How would you construct confidence intervals for LLM outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.17: A/B Testing with Network Effects\n",
    "\n",
    "**Reference**: [Causal Inference with Dyadic Data (arxiv 2025)](https://arxiv.org/html/2505.20780)\n",
    "\n",
    "Modern A/B tests must account for interference when users interact.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate a social network with 1000 users and random connections\n",
    "2. Implement a treatment where treated users have probability p=0.6 of success vs p=0.5 for control\n",
    "3. Add network spillover: neighbors of treated users also get a small boost (p+0.05)\n",
    "4. Randomly assign 500 users to treatment, 500 to control\n",
    "5. Compare:\n",
    "   - Naive estimate: difference in means ignoring spillover\n",
    "   - Adjusted estimate accounting for network exposure\n",
    "6. Construct confidence intervals for the true treatment effect\n",
    "7. How does spillover bias the naive estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.18: Statistical Inference for Neural Network Predictions\n",
    "\n",
    "**Reference**: [A Modern Take on Bias-Variance Tradeoff in Neural Networks (2025)](https://arxiv.org/abs/1810.08591)\n",
    "\n",
    "Neural networks are trained with stochastic optimization, creating uncertainty in predictions.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create a simple regression dataset\n",
    "2. Train a small neural network (2 hidden layers) 50 times with different random initializations\n",
    "3. For a fixed test input x*, collect all 50 predictions\n",
    "4. Analyze the distribution of predictions:\n",
    "   - Calculate mean prediction and standard deviation\n",
    "   - Construct a 95% prediction interval\n",
    "5. Compare this to the sampling distribution approach:\n",
    "   - Generate 50 different training datasets (bootstrap)\n",
    "   - Train one network on each\n",
    "   - How does this uncertainty compare to initialization uncertainty?\n",
    "6. Propose a method to quantify total predictive uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.19: LLM Survey Simulation and Statistical Inference\n",
    "\n",
    "**Reference**: [How Many Survey Respondents is an LLM Worth? (arxiv 2025)](https://arxiv.org/abs/2502.17773)\n",
    "\n",
    "Researchers use LLMs to simulate survey responses. We need statistical methods to validate these simulations.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate a \"true\" population with binary opinions (60% favor, 40% oppose)\n",
    "2. Create an \"LLM simulator\" that generates responses with some bias (65% favor, 35% oppose)\n",
    "3. Draw samples of size n=[50, 100, 200, 500] from both populations\n",
    "4. For each sample size:\n",
    "   - Calculate the proportion favoring\n",
    "   - Construct 95% confidence intervals\n",
    "   - Test H₀: p_true = p_LLM\n",
    "5. At what sample size can you reliably detect the 5% bias?\n",
    "6. Propose a method to adjust LLM simulations to match true population parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.20: Confidence Intervals for LLM Reward Models\n",
    "\n",
    "**Reference**: [Uncertainty Quantification for LLM Reward Learning (arxiv 2025)](https://arxiv.org/abs/2512.03208)\n",
    "\n",
    "Reward models in RLHF need confidence intervals for their reward estimates.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate a reward model that scores text completions from 0-10\n",
    "2. Generate 1000 human feedback examples with true rewards drawn from N(μ=7, σ=2)\n",
    "3. Train a simple reward predictor (linear model on text features)\n",
    "4. For new completions, the predictor gives point estimates\n",
    "5. Implement three approaches to construct 95% confidence intervals:\n",
    "   - Bootstrap: resample training data, retrain, get prediction distribution\n",
    "   - Asymptotic: use standard error from model fitting\n",
    "   - Empirical: use residuals from training data\n",
    "6. Evaluate coverage: do 95% of intervals contain true rewards?\n",
    "7. Which method gives the most reliable intervals? The tightest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise Completion Checklist\n",
    "\n",
    "- [ ] Exercises 1-5: Fundamental concepts\n",
    "- [ ] Exercises 6-10: Advanced statistical problems\n",
    "- [ ] Exercises 11-15: AI/ML applications\n",
    "- [ ] Exercises 16-20: Contemporary 2025+ problems\n",
    "\n",
    "---\n",
    "\n",
    "<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white; text-align: center;'>\n",
    "<p style='margin: 0; font-size: 1.1em;'>Exercises curated by <strong>PLAI Academy</strong></p>\n",
    "<p style='margin: 5px 0 0 0; opacity: 0.8;'>Statistical Inference • 2025</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
