{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Common Hypothesis Tests\n",
    "\n",
    "**Core Goal:** Apply hypothesis testing to common research questions using appropriate test procedures.\n",
    "\n",
    "**Motivation:** Chapter 6 established the theoretical framework for hypothesis testing. This chapter presents specific tests for common scenarios: comparing means, comparing proportions, testing independence, and alternatives when assumptions fail. These tests are the workhorses of applied statistics, appearing daily in research across all fields. Understanding when to use each test and how to interpret results is essential for practitioners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 One-Sample t-Test\n",
    "\n",
    "**Use case:** Test whether population mean equals a specified value.\n",
    "\n",
    "**Hypotheses:** H₀: μ = μ₀ versus H₁: μ ≠ μ₀ (or one-sided)\n",
    "\n",
    "**Test statistic:** $T = \\frac{\\bar{X} - \\mu_0}{S/\\sqrt{n}} \\sim t_{n-1}$ under H₀\n",
    "\n",
    "**Assumptions:** Data are random sample from normal distribution (or large n by Central Limit Theorem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Test if mean height differs from 170 cm\n",
    "heights = stats.norm(172, 8).rvs(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.ttest_1samp: One-sample t-test\n",
    "t_result = stats.ttest_1samp(heights, 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {np.mean(heights):.2f} cm\")\n",
    "print(f\"t-statistic: {t_result.statistic:.3f}, p-value: {t_result.pvalue:.4f}\")\n",
    "print(f\"Decision at α=0.05: {'Reject H₀' if t_result.pvalue < 0.05 else 'Fail to reject H₀'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Two-Sample t-Test (Independent Samples)\n",
    "\n",
    "**Use case:** Compare means of two independent groups.\n",
    "\n",
    "**Hypotheses:** H₀: μ₁ = μ₂ versus H₁: μ₁ ≠ μ₂\n",
    "\n",
    "**Welch's t-test (unequal variances):** $T = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}$\n",
    "\n",
    "**Assumptions:** Independent random samples from normal distributions (or large n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare treatment versus control\n",
    "control = stats.norm(100, 15).rvs(40)\n",
    "treatment = stats.norm(108, 18).rvs(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.ttest_ind: Independent two-sample t-test (Welch's by default)\n",
    "t2_result = stats.ttest_ind(treatment, control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Control mean: {np.mean(control):.2f}, Treatment mean: {np.mean(treatment):.2f}\")\n",
    "print(f\"t-statistic: {t2_result.statistic:.3f}, p-value: {t2_result.pvalue:.4f}\")\n",
    "print(f\"Decision: {'Reject H₀ - means differ' if t2_result.pvalue < 0.05 else 'Fail to reject H₀'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Paired t-Test\n",
    "\n",
    "**Use case:** Compare means when observations are paired (before/after, matched pairs).\n",
    "\n",
    "**Approach:** Test whether mean of differences equals zero.\n",
    "\n",
    "**Test statistic:** $T = \\frac{\\bar{D}}{S_D/\\sqrt{n}}$ where $D_i = X_i - Y_i$\n",
    "\n",
    "**Assumptions:** Differences are normally distributed (or large n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before and after measurements on same subjects\n",
    "before = stats.norm(80, 10).rvs(25)\n",
    "after = before + stats.norm(5, 8).rvs(25)  # Correlated measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.ttest_rel: Paired t-test\n",
    "paired_result = stats.ttest_rel(after, before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean difference (after - before): {np.mean(after - before):.2f}\")\n",
    "print(f\"t-statistic: {paired_result.statistic:.3f}, p-value: {paired_result.pvalue:.4f}\")\n",
    "print(f\"Decision: {'Significant change' if paired_result.pvalue < 0.05 else 'No significant change'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Test for Proportion\n",
    "\n",
    "**Use case:** Test whether population proportion equals a specified value.\n",
    "\n",
    "**Hypotheses:** H₀: p = p₀ versus H₁: p ≠ p₀\n",
    "\n",
    "**Test statistic:** $Z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\sim N(0,1)$ for large n\n",
    "\n",
    "**Assumptions:** Large sample (np₀ ≥ 10 and n(1-p₀) ≥ 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if proportion differs from 0.5\n",
    "n_trials = 200; n_successes = 115; p_0 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p̂ = x/n: Sample proportion\n",
    "p_hat = n_successes / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = (p̂ - p₀)/SE(p̂): Test statistic for proportion\n",
    "se_p0 = np.sqrt(p_0 * (1 - p_0) / n_trials)\n",
    "z_stat = (p_hat - p_0) / se_p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value from standard normal\n",
    "p_value_prop = 2 * (1 - stats.norm.cdf(abs(z_stat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sample proportion: p̂ = {p_hat:.3f}\")\n",
    "print(f\"Z-statistic: {z_stat:.3f}, p-value: {p_value_prop:.4f}\")\n",
    "print(f\"Decision: {'Reject H₀' if p_value_prop < 0.05 else 'Fail to reject H₀'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Two-Proportion Z-Test\n",
    "\n",
    "**Use case:** Compare proportions from two independent groups.\n",
    "\n",
    "**Hypotheses:** H₀: p₁ = p₂ versus H₁: p₁ ≠ p₂\n",
    "\n",
    "**Pooled proportion:** $\\hat{p} = \\frac{x_1 + x_2}{n_1 + n_2}$\n",
    "\n",
    "**Test statistic:** $Z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_1} + \\frac{1}{n_2})}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare success rates in two groups\n",
    "n1, x1 = 100, 42  # Group 1\n",
    "n2, x2 = 120, 60  # Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_hat = x1/n1; p2_hat = x2/n2\n",
    "p_pooled = (x1 + x2) / (n1 + n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE under H₀ using pooled proportion\n",
    "se_diff = np.sqrt(p_pooled * (1 - p_pooled) * (1/n1 + 1/n2))\n",
    "z_2prop = (p1_hat - p2_hat) / se_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_2prop = 2 * (1 - stats.norm.cdf(abs(z_2prop)))\n",
    "print(f\"p̂₁ = {p1_hat:.3f}, p̂₂ = {p2_hat:.3f}\")\n",
    "print(f\"Z = {z_2prop:.3f}, p-value = {p_value_2prop:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Chi-Squared Goodness-of-Fit Test\n",
    "\n",
    "**Use case:** Test whether observed frequencies match expected distribution.\n",
    "\n",
    "**Test statistic:** $\\chi^2 = \\sum_{i=1}^k \\frac{(O_i - E_i)^2}{E_i} \\sim \\chi^2_{k-1-p}$\n",
    "\n",
    "where $O_i$ = observed, $E_i$ = expected, $p$ = number of estimated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if die is fair\n",
    "observed = np.array([15, 18, 12, 19, 16, 20])  # Rolls of 1-6\n",
    "expected = np.array([100/6] * 6)  # Fair die expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.chisquare: Chi-squared goodness-of-fit test\n",
    "chi2_result = stats.chisquare(observed, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"χ² statistic: {chi2_result.statistic:.3f}, p-value: {chi2_result.pvalue:.4f}\")\n",
    "print(f\"Decision: {'Die is not fair' if chi2_result.pvalue < 0.05 else 'Consistent with fair die'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 Chi-Squared Test of Independence\n",
    "\n",
    "**Use case:** Test whether two categorical variables are independent.\n",
    "\n",
    "**Test statistic:** $\\chi^2 = \\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$\n",
    "\n",
    "**Degrees of freedom:** $(r-1)(c-1)$ for $r \\times c$ table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test independence of treatment and outcome\n",
    "contingency_table = np.array([[30, 10],   # Treatment A: Success, Failure\n",
    "                               [20, 25]])  # Treatment B: Success, Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.chi2_contingency: Chi-squared test of independence\n",
    "chi2_ind = stats.chi2_contingency(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"χ² statistic: {chi2_ind.statistic:.3f}, p-value: {chi2_ind.pvalue:.4f}\")\n",
    "print(f\"Decision: {'Variables are dependent' if chi2_ind.pvalue < 0.05 else 'Variables appear independent'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 Mann-Whitney U Test (Wilcoxon Rank-Sum)\n",
    "\n",
    "**Use case:** Non-parametric alternative to two-sample t-test.\n",
    "\n",
    "**When to use:** Comparing two groups when normality assumption questionable or data are ordinal.\n",
    "\n",
    "**Hypotheses:** H₀: distributions are identical versus H₁: one distribution tends to have larger values\n",
    "\n",
    "**Method:** Rank all observations, sum ranks for each group, compare to expected under H₀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare two groups without assuming normality\n",
    "group_a = stats.expon(scale=2).rvs(30)  # Non-normal (exponential)\n",
    "group_b = stats.expon(scale=2.5).rvs(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.mannwhitneyu: Mann-Whitney U test (non-parametric)\n",
    "mw_result = stats.mannwhitneyu(group_a, group_b, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mann-Whitney U statistic: {mw_result.statistic:.0f}, p-value: {mw_result.pvalue:.4f}\")\n",
    "print(f\"Decision: {'Groups differ' if mw_result.pvalue < 0.05 else 'No significant difference'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.9 Wilcoxon Signed-Rank Test\n",
    "\n",
    "**Use case:** Non-parametric alternative to paired t-test.\n",
    "\n",
    "**When to use:** Paired data when normality of differences questionable.\n",
    "\n",
    "**Method:** Rank absolute differences, sum ranks of positive (or negative) differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired data, non-normal differences\n",
    "before_exp = stats.gamma(2, scale=2).rvs(20)\n",
    "after_exp = before_exp + stats.expon(scale=1).rvs(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.wilcoxon: Wilcoxon signed-rank test (non-parametric paired)\n",
    "wilcox_result = stats.wilcoxon(after_exp, before_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Wilcoxon statistic: {wilcox_result.statistic:.0f}, p-value: {wilcox_result.pvalue:.4f}\")\n",
    "print(f\"Decision: {'Significant change' if wilcox_result.pvalue < 0.05 else 'No significant change'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.10 Choosing the Right Test\n",
    "\n",
    "| **Scenario** | **Test** | **Assumptions** |\n|
|------------|---------|----------------|\n",
| One mean versus value | One-sample t-test | Normality or large n |\n|
| Two independent means | Two-sample t-test (Welch's) | Normality or large n |\n|
| Two paired means | Paired t-test | Normality of differences or large n |\n|
| One proportion versus value | One-proportion Z-test | Large n |\n|
| Two independent proportions | Two-proportion Z-test | Large n |\n|
| Goodness of fit | Chi-squared | Expected counts ≥ 5 |\n|
| Independence | Chi-squared | Expected counts ≥ 5 |\n|
| Two groups, non-normal | Mann-Whitney U | None (non-parametric) |\n|
| Paired, non-normal | Wilcoxon signed-rank | None (non-parametric) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Test selection depends on:**\n",
    "1. **Type of data:** Continuous, binary, categorical\n",
    "2. **Research question:** Compare means? Test independence? Goodness of fit?\n",
    "3. **Study design:** Independent groups? Paired? Single sample?\n",
    "4. **Assumptions:** Normal? Large sample? Equal variances?\n",
    "\n",
    "**When assumptions violated:** Use non-parametric alternatives or bootstrap methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **Match test to research question and data type:** Different scenarios require different tests. Proper selection is crucial.\n",
    "\n",
    "- **Parametric tests assume distributional form:** t-tests assume normality (or rely on Central Limit Theorem for large n).\n",
    "\n",
    "- **Non-parametric tests are robust alternatives:** When normality questionable, use Mann-Whitney or Wilcoxon tests.\n",
    "\n",
    "- **Paired designs increase power:** Paired t-test accounts for correlation, increasing power over independent samples.\n",
    "\n",
    "- **Chi-squared tests for categorical data:** Use for goodness-of-fit and independence testing with count data.\n",
    "\n",
    "- **Check assumptions before testing:** Normality, independence, and adequate sample size matter for validity.\n",
    "\n",
    "- **Effect size matters alongside p-value:** Statistical significance doesn't guarantee practical importance.\n",
    "\n",
    "- **Non-parametric tests sacrifice power for robustness:** Less powerful than parametric counterparts when assumptions hold, but more reliable when violated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
