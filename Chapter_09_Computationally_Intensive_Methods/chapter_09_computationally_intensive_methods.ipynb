{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Computationally Intensive Methods\n",
    "\n",
    "**Core Goal:** Use computational power to perform inference when analytical solutions are intractable or distributional assumptions are uncertain.\n",
    "\n",
    "**Motivation:** Classical statistical inference relies on mathematical theory: closed-form distributions, asymptotic approximations, and strong parametric assumptions. Many real-world problems do not fit this framework—distributions are unknown, parameters are high-dimensional, or exact sampling distributions are mathematically intractable. Modern computational power enables a different approach: simulate, resample, and iterate to approximate distributions empirically. These computationally intensive methods trade mathematical elegance for practical applicability, providing valid inference with minimal assumptions. They represent a paradigm shift from analytical derivation to computational approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Monte Carlo Methods\n",
    "\n",
    "**Monte Carlo Method:** Use random sampling to approximate quantities that are difficult or impossible to compute analytically.\n",
    "\n",
    "**Core Principle:** If we can simulate from a distribution, we can approximate any expectation: $E[g(X)] \\approx \\frac{1}{N}\\sum_{i=1}^N g(X_i)$ where $X_1, ..., X_N$ are independent samples.\n",
    "\n",
    "**Motivation:** Many statistical quantities involve integrals that have no closed form: expected values, probabilities, variances. Monte Carlo methods replace integration with simulation: draw many samples, compute the quantity for each sample, average the results. By the Law of Large Numbers, this approximation converges to the true value as the number of simulations increases. Monte Carlo is particularly powerful for high-dimensional problems where traditional numerical integration becomes infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Estimating π\n",
    "\n",
    "**Method:** Simulate uniform points in square $[0,1] \\times [0,1]$. Fraction inside unit circle ≈ $\\pi/4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate N random points in unit square\n",
    "N = 100000\n",
    "x, y = np.random.uniform(0, 1, N), np.random.uniform(0, 1, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count points inside quarter-circle: x² + y² ≤ 1\n",
    "inside_circle = (x**2 + y**2) <= 1\n",
    "pi_estimate = 4 * np.mean(inside_circle)\n",
    "print(f\"π estimate from {N} simulations: {pi_estimate:.5f}\")\n",
    "print(f\"True π: {np.pi:.5f}, Error: {abs(pi_estimate - np.pi):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Integration\n",
    "\n",
    "**Problem:** Compute $\\int_a^b h(x)dx$ when $h$ has no closed-form antiderivative.\n",
    "\n",
    "**Solution:** If $X \\sim \\text{Uniform}(a, b)$, then $\\int_a^b h(x)dx = (b-a)E[h(X)] \\approx (b-a)\\frac{1}{N}\\sum_{i=1}^N h(X_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate integral of exp(x²) from 0 to 1\n",
    "def h(x):\n",
    "    return np.exp(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo: Sample uniform on [0,1], evaluate h, average\n",
    "samples = np.random.uniform(0, 1, 10000)\n",
    "integral_estimate = 1.0 * np.mean(h(samples))\n",
    "print(f\"Monte Carlo integral estimate: {integral_estimate:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Error of Monte Carlo Estimate:** $\\text{SE} = \\frac{\\sigma}{\\sqrt{N}}$ where $\\sigma$ is standard deviation of $h(X)$. Accuracy increases with $\\sqrt{N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Standard Error: σ/√N\n",
    "mc_se = np.std(h(samples)) / np.sqrt(len(samples))\n",
    "print(f\"Monte Carlo Standard Error: {mc_se:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Permutation Tests\n",
    "\n",
    "**Permutation Test:** Exact non-parametric test based on permuting group labels to generate the null distribution.\n",
    "\n",
    "**Null Hypothesis:** Two samples come from the same distribution (treatment has no effect).\n",
    "\n",
    "**Procedure:**\n",
    "1. Compute test statistic $T_{obs}$ from observed data\n",
    "2. Pool all observations, randomly permute group labels\n",
    "3. Compute test statistic $T_{perm}$ for permuted data\n",
    "4. Repeat steps 2-3 many times to build null distribution\n",
    "5. p-value = proportion of permutations where $|T_{perm}| \\geq |T_{obs}|$\n",
    "\n",
    "**Motivation:** Under the null hypothesis of no treatment effect, group labels are arbitrary—any permutation of labels is equally likely. The permutation test exploits this by generating the exact null distribution through all (or many random) permutations. This provides an exact test without distributional assumptions. It is particularly powerful for small samples where asymptotic approximations may be inaccurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two groups: Test if treatment has an effect\n",
    "np.random.seed(42)\n",
    "control = stats.norm(50, 10).rvs(15)\n",
    "treatment = stats.norm(55, 10).rvs(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed test statistic: Difference in means\n",
    "obs_diff = np.mean(treatment) - np.mean(control)\n",
    "print(f\"Observed difference in means: {obs_diff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation test: Randomly shuffle group labels, recompute statistic\n",
    "combined = np.concatenate([control, treatment])\n",
    "n_control = len(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate null distribution through permutation\n",
    "n_permutations = 10000\n",
    "permuted_diffs = []\n",
    "for _ in range(n_permutations):\n",
    "    permuted = np.random.permutation(combined)\n",
    "    perm_control, perm_treatment = permuted[:n_control], permuted[n_control:]\n",
    "    permuted_diffs.append(np.mean(perm_treatment) - np.mean(perm_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value = proportion of permutations as extreme as observed\n",
    "p_value_perm = np.mean(np.abs(permuted_diffs) >= np.abs(obs_diff))\n",
    "print(f\"Permutation test p-value: {p_value_perm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with parametric t-test\n",
    "t_result = stats.ttest_ind(treatment, control)\n",
    "print(f\"t-test p-value: {t_result.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(permuted_diffs, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(obs_diff, color='r', linewidth=2, label='Observed difference')\n",
    "plt.axvline(-obs_diff, color='r', linewidth=2, linestyle='--')\n",
    "plt.xlabel('Difference in Means'); plt.ylabel('Density')\n",
    "plt.title('Permutation Distribution Under Null Hypothesis'); plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of Permutation Tests:**\n",
    "- Exact: No reliance on asymptotic approximations\n",
    "- Distribution-free: No assumption of normality\n",
    "- Flexible: Can use any test statistic (mean difference, median difference, variance ratio, etc.)\n",
    "\n",
    "**Limitation:** Computationally intensive for large samples (though usually 10000 permutations suffice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Bootstrap (Advanced Applications)\n",
    "\n",
    "**Bootstrap Principle:** The sample is to the population as the bootstrap sample is to the sample.\n",
    "\n",
    "**Motivation:** Bootstrap extends beyond simple Standard Error estimation (Chapter 8). Advanced applications include: bias correction, confidence intervals via bootstrap-t, hypothesis testing, and multivariate inference. The bootstrap is particularly valuable for complex statistics where theoretical distributions are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Bias Correction\n",
    "\n",
    "**Bootstrap Bias Estimate:** $\\widehat{\\text{Bias}} = \\bar{\\theta}^* - \\hat{\\theta}$ where $\\bar{\\theta}^*$ is mean of bootstrap estimates.\n",
    "\n",
    "**Bias-Corrected Estimator:** $\\hat{\\theta}_{corrected} = 2\\hat{\\theta} - \\bar{\\theta}^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Estimate correlation coefficient (can be biased in small samples)\n",
    "np.random.seed(42)\n",
    "x = stats.norm(0, 1).rvs(20)\n",
    "y = 0.5 * x + stats.norm(0, 1).rvs(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original estimate: r = corr(x, y)\n",
    "original_corr = np.corrcoef(x, y)[0, 1]\n",
    "print(f\"Original correlation estimate: {original_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap bias correction: Resample pairs (x, y)\n",
    "n_bootstrap = 5000\n",
    "bootstrap_corrs = []\n",
    "for _ in range(n_bootstrap):\n",
    "    indices = np.random.choice(len(x), len(x), replace=True)\n",
    "    bootstrap_corrs.append(np.corrcoef(x[indices], y[indices])[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias = E[r*] - r: Difference between bootstrap mean and original estimate\n",
    "bootstrap_bias = np.mean(bootstrap_corrs) - original_corr\n",
    "corrected_corr = 2 * original_corr - np.mean(bootstrap_corrs)\n",
    "print(f\"Bootstrap bias estimate: {bootstrap_bias:.4f}\")\n",
    "print(f\"Bias-corrected correlation: {corrected_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap-t Confidence Interval\n",
    "\n",
    "**Method:** Use bootstrap to estimate the distribution of the studentized statistic $T = \\frac{\\hat{\\theta} - \\theta}{\\widehat{SE}(\\hat{\\theta})}$.\n",
    "\n",
    "**Advantage:** Better small-sample performance than percentile method, especially for skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data and estimate\n",
    "data = stats.expon(scale=10).rvs(30)\n",
    "original_mean = np.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double bootstrap: For each bootstrap sample, compute SE via nested bootstrap\n",
    "n_bootstrap = 1000\n",
    "bootstrap_t_statistics = []\n",
    "for _ in range(n_bootstrap):\n",
    "    boot_sample = np.random.choice(data, len(data), replace=True)\n",
    "    boot_mean = np.mean(boot_sample)\n",
    "    # Nested bootstrap to estimate SE\n",
    "    nested_means = [np.mean(np.random.choice(boot_sample, len(boot_sample), replace=True)) for _ in range(100)]\n",
    "    boot_se = np.std(nested_means)\n",
    "    if boot_se > 0:\n",
    "        t_stat = (boot_mean - original_mean) / boot_se\n",
    "        bootstrap_t_statistics.append(t_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap-t Confidence Interval: θ̂ - t*₁₋α/₂ × SE, θ̂ - t*α/₂ × SE\n",
    "original_se = np.std(data) / np.sqrt(len(data))\n",
    "t_quantiles = np.percentile(bootstrap_t_statistics, [97.5, 2.5])\n",
    "bootstrap_t_ci = [original_mean - t_quantiles[0] * original_se, \n",
    "                  original_mean - t_quantiles[1] * original_se]\n",
    "print(f\"Bootstrap-t 95% Confidence Interval: [{bootstrap_t_ci[0]:.2f}, {bootstrap_t_ci[1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Cross-Validation\n",
    "\n",
    "**Cross-Validation:** Method for assessing model performance by training on one subset of data and testing on another.\n",
    "\n",
    "**k-Fold Cross-Validation:**\n",
    "1. Split data into k folds\n",
    "2. For each fold: train on remaining k-1 folds, test on held-out fold\n",
    "3. Average performance across all k folds\n",
    "\n",
    "**Motivation:** Evaluating model performance on the same data used for training leads to overly optimistic assessments. Cross-validation provides an honest estimate of out-of-sample performance by systematically holding out different subsets for testing. It is particularly important for model selection (choosing between competing models) and tuning hyperparameters. Leave-one-out cross-validation (k=n) provides nearly unbiased performance estimates but is computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data: y = x + x² + noise\n",
    "np.random.seed(42)\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = x + x**2 + np.random.normal(0, 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare linear vs quadratic model using 5-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model: y ~ x\n",
    "linear_model = LinearRegression()\n",
    "linear_scores = cross_val_score(linear_model, x.reshape(-1, 1), y, \n",
    "                                cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Linear model CV Mean Squared Error: {-linear_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic model: y ~ x + x²\n",
    "quadratic_model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "quadratic_scores = cross_val_score(quadratic_model, x.reshape(-1, 1), y,\n",
    "                                  cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Quadratic model CV Mean Squared Error: {-quadratic_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** Cross-validation correctly identifies that quadratic model fits better (lower Mean Squared Error), as the true relationship includes x²."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation\n",
    "\n",
    "**Leave-One-Out:** Special case where k = n. Train on n-1 observations, test on the single held-out observation.\n",
    "\n",
    "**Advantage:** Nearly unbiased estimate of prediction error.\n",
    "\n",
    "**Disadvantage:** Computationally expensive (requires n model fits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Out Cross-Validation: k = n\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo_scores = cross_val_score(quadratic_model, x.reshape(-1, 1), y,\n",
    "                             cv=LeaveOneOut(), scoring='neg_mean_squared_error')\n",
    "print(f\"Leave-One-Out CV Mean Squared Error: {-loo_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 Jackknife\n",
    "\n",
    "**Jackknife:** Resampling method that systematically leaves out one observation at a time.\n",
    "\n",
    "**Jackknife Estimate of Standard Error:** $\\widehat{SE}_{jack} = \\sqrt{\\frac{n-1}{n}\\sum_{i=1}^n(\\hat{\\theta}_{(-i)} - \\bar{\\theta}_{(\\cdot)})^2}$\n",
    "\n",
    "where $\\hat{\\theta}_{(-i)}$ is estimate with $i$-th observation removed, $\\bar{\\theta}_{(\\cdot)}$ is average of jackknife estimates.\n",
    "\n",
    "**Motivation:** The jackknife predates the bootstrap and provides similar functionality with less computation. By systematically removing each observation and recomputing the statistic, it assesses how sensitive the estimate is to individual observations. This sensitivity translates to an estimate of variability. While bootstrap is more general and accurate, jackknife is simpler and often adequate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jackknife Standard Error for median\n",
    "data = stats.norm(50, 10).rvs(30)\n",
    "original_median = np.median(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute θ̂₍₋ᵢ₎: Estimate with each observation removed\n",
    "jackknife_estimates = []\n",
    "for i in range(len(data)):\n",
    "    jackknife_sample = np.delete(data, i)\n",
    "    jackknife_estimates.append(np.median(jackknife_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jackknife Standard Error: √[(n-1)/n × Σ(θ̂₍₋ᵢ₎ - θ̄₍·₎)²]\n",
    "n = len(data)\n",
    "theta_bar = np.mean(jackknife_estimates)\n",
    "jackknife_se = np.sqrt((n-1)/n * np.sum((np.array(jackknife_estimates) - theta_bar)**2))\n",
    "print(f\"Jackknife Standard Error of median: {jackknife_se:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with bootstrap Standard Error\n",
    "bootstrap_medians = [np.median(np.random.choice(data, len(data), replace=True)) for _ in range(5000)]\n",
    "bootstrap_se = np.std(bootstrap_medians)\n",
    "print(f\"Bootstrap Standard Error of median: {bootstrap_se:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison:** Jackknife and bootstrap often give similar Standard Error estimates. Bootstrap is more flexible (works for any statistic) and more accurate for complex estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Markov Chain Monte Carlo\n",
    "\n",
    "**Markov Chain Monte Carlo:** Methods for sampling from complex distributions by constructing a Markov chain whose stationary distribution is the target distribution.\n",
    "\n",
    "**Problem:** Want to sample from $p(\\theta | \\text{data})$, but direct sampling is impossible (distribution is known only up to a constant, or is very high-dimensional).\n",
    "\n",
    "**Solution:** Construct a Markov chain that \"wanders\" through the parameter space, visiting regions in proportion to their probability under the target distribution.\n",
    "\n",
    "**Motivation:** Many posterior distributions in Bayesian inference, likelihood functions in complex models, and high-dimensional distributions cannot be sampled directly. Markov Chain Monte Carlo provides a general-purpose sampling algorithm that requires only the ability to evaluate the target density up to a proportionality constant. Once we have samples from the distribution, we can compute any expectation or quantile. This enables Bayesian inference, complex model fitting, and high-dimensional integration that would be impossible analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings Algorithm\n",
    "\n",
    "**Algorithm:**\n",
    "1. Start at initial value $\\theta^{(0)}$\n",
    "2. Propose new value: $\\theta^* \\sim q(\\theta^* | \\theta^{(t)})$\n",
    "3. Compute acceptance probability: $\\alpha = \\min\\left(1, \\frac{p(\\theta^*)q(\\theta^{(t)}|\\theta^*)}{p(\\theta^{(t)})q(\\theta^*|\\theta^{(t)})}\\right)$\n",
    "4. With probability $\\alpha$: accept $\\theta^{(t+1)} = \\theta^*$, otherwise $\\theta^{(t+1)} = \\theta^{(t)}$\n",
    "5. Repeat steps 2-4\n",
    "\n",
    "**Key Property:** After sufficient iterations (burn-in), samples approximate the target distribution $p(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sample from mixture of normals using Metropolis-Hastings\n",
    "# Target: 0.3×N(0,1) + 0.7×N(5,1)\n",
    "def target_density(x):\n",
    "    return 0.3 * stats.norm(0, 1).pdf(x) + 0.7 * stats.norm(5, 1).pdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis-Hastings with Normal proposal: q(θ*|θ) = N(θ, σ²)\n",
    "def metropolis_hastings(target, n_iterations, proposal_sd=1.0):\n",
    "    samples = [0]  # Start at θ = 0\n",
    "    for _ in range(n_iterations):\n",
    "        current = samples[-1]\n",
    "        proposed = current + np.random.normal(0, proposal_sd)\n",
    "        # Acceptance probability: α = min(1, p(θ*)/p(θ))\n",
    "        acceptance_prob = min(1, target(proposed) / target(current))\n",
    "        if np.random.uniform() < acceptance_prob:\n",
    "            samples.append(proposed)\n",
    "        else:\n",
    "            samples.append(current)\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Markov Chain Monte Carlo\n",
    "np.random.seed(42)\n",
    "samples = metropolis_hastings(target_density, n_iterations=10000)\n",
    "print(f\"Acceptance rate: {np.mean(np.diff(samples) != 0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard burn-in (first 1000 samples)\n",
    "burn_in = 1000\n",
    "samples_after_burnin = samples[burn_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Markov Chain Monte Carlo samples with true distribution\n",
    "x_grid = np.linspace(-4, 8, 200)\n",
    "plt.hist(samples_after_burnin, bins=50, density=True, alpha=0.7, label='Markov Chain Monte Carlo samples', edgecolor='black')\n",
    "plt.plot(x_grid, [target_density(x) for x in x_grid], 'r-', linewidth=2, label='True density')\n",
    "plt.xlabel('θ'); plt.ylabel('Density'); plt.title('Metropolis-Hastings Sampling')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diagnostics:**\n",
    "- **Trace plot:** Plot $\\theta^{(t)}$ versus $t$ to check convergence and mixing\n",
    "- **Autocorrelation:** Check correlation between $\\theta^{(t)}$ and $\\theta^{(t+k)}$ (should decay rapidly)\n",
    "- **Multiple chains:** Run several chains from different starting points; should converge to same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plot: Shows how chain explores parameter space\n",
    "plt.plot(samples[:2000])\n",
    "plt.xlabel('Iteration'); plt.ylabel('θ'); plt.title('Trace Plot (First 2000 iterations)')\n",
    "plt.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.axhline(5, color='gray', linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.7 Practical Considerations\n",
    "\n",
    "**Choosing Number of Simulations:**\n",
    "- **Monte Carlo Standard Error:** $\\text{SE} \\propto 1/\\sqrt{N}$\n",
    "- To reduce Standard Error by factor of 10, need 100× more simulations\n",
    "- Typical choices: 1000 for rough approximation, 10000 for publishable results\n",
    "\n",
    "**Computational Cost versus Statistical Accuracy:**\n",
    "- Law of diminishing returns: doubling simulations only improves accuracy by $\\sqrt{2}$\n",
    "- Often better to improve simulation design (variance reduction, importance sampling) than just adding more samples\n",
    "\n",
    "**Parallel Computing:**\n",
    "- Bootstrap, permutation tests, and Monte Carlo methods are \"embarrassingly parallel\"\n",
    "- Can achieve near-linear speedup with multiple processors\n",
    "\n",
    "**When to Use Computational Methods:**\n",
    "- Distribution is unknown or complex\n",
    "- Analytical solution is intractable\n",
    "- Small sample size makes asymptotics questionable\n",
    "- Want distribution-free inference\n",
    "- High-dimensional problems where traditional methods fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Computational Inference Framework\n",
    "\n",
    "**Simulation-based methods trade mathematical theory for computational approximation:**\n",
    "\n",
    "**Monte Carlo Integration:**\n",
    "- Replace integrals with sample averages\n",
    "- Accuracy increases with $\\sqrt{N}$\n",
    "- Useful for expectations, probabilities, and high-dimensional integrals\n",
    "\n",
    "**Permutation Tests:**\n",
    "- Generate exact null distribution by permuting labels\n",
    "- Exact and distribution-free\n",
    "- Flexible: can use any test statistic\n",
    "\n",
    "**Bootstrap:**\n",
    "- Resample from observed data to approximate sampling distribution\n",
    "- Provides Standard Errors, bias correction, confidence intervals\n",
    "- Works for complex statistics without theory\n",
    "\n",
    "**Cross-Validation:**\n",
    "- Assess out-of-sample model performance\n",
    "- Essential for model selection and hyperparameter tuning\n",
    "- k-fold balances computation and accuracy\n",
    "\n",
    "**Jackknife:**\n",
    "- Systematic leave-one-out resampling\n",
    "- Simpler than bootstrap but less flexible\n",
    "- Useful for Standard Error estimation\n",
    "\n",
    "**Markov Chain Monte Carlo:**\n",
    "- Sample from complex distributions via Markov chains\n",
    "- Enables Bayesian inference and high-dimensional integration\n",
    "- Requires burn-in and diagnostic checking\n",
    "\n",
    "**Common theme:** When theory is hard, simulate. Modern computational power makes methods once considered impractical now routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- **Computation enables inference without strong assumptions:** Monte Carlo, bootstrap, and permutation tests provide valid inference with minimal distributional assumptions, making them more broadly applicable than classical methods.\n",
    "\n",
    "- **Accuracy improves slowly with simulation size:** Monte Carlo Standard Error decreases as $1/\\sqrt{N}$, so quadrupling simulations only doubles accuracy. This limits practical precision but is usually sufficient for statistical inference.\n",
    "\n",
    "- **Permutation tests are exact and distribution-free:** By generating the null distribution through all permutations of labels, permutation tests provide exact p-values without assuming normality or relying on asymptotics.\n",
    "\n",
    "- **Bootstrap is remarkably general:** It works for any statistic (mean, median, correlation, regression coefficients) and provides Standard Errors, bias correction, and confidence intervals using only the observed sample.\n",
    "\n",
    "- **Cross-validation prevents overfitting:** Training and testing on the same data gives overly optimistic performance estimates. Cross-validation provides honest assessment of out-of-sample performance.\n",
    "\n",
    "- **Markov Chain Monte Carlo enables Bayesian inference:** By constructing Markov chains that sample from posterior distributions, Markov Chain Monte Carlo makes Bayesian inference practical for complex models where analytical solutions are impossible.\n",
    "\n",
    "- **Computational methods are embarrassingly parallel:** Bootstrap iterations, permutation replicates, and Monte Carlo simulations are independent, allowing near-linear speedup with multiple processors. This makes large-scale computational inference feasible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
